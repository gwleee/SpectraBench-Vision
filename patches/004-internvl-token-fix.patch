--- a/vlmeval/vlm/internvl/internvl_chat.py
+++ b/vlmeval/vlm/internvl/internvl_chat.py
@@ -1,4 +1,5 @@
 import math
+import os
 import pandas as pd
 import random
 import re
@@ -155,7 +156,11 @@ class InternVLChat(BaseModel):
         assert osp.exists(model_path) or splitlen(model_path) == 2
 
         self.model_path = model_path
-        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, use_fast=False)
+        
+        # Get HuggingFace token from environment
+        token = os.getenv('HUGGING_FACE_HUB_TOKEN') or os.getenv('HF_TOKEN')
+        token_kwargs = {'token': token} if token else {}
+        
+        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, use_fast=False, **token_kwargs)
 
         # Regular expression to match the pattern 'Image' followed by a number, e.g. Image1
@@ -185,6 +190,7 @@ class InternVLChat(BaseModel):
             self.device = 'cuda'
         else:
             self.model = AutoModel.from_pretrained(
                 model_path,
                 torch_dtype=torch.bfloat16,
+                **token_kwargs,
@@ -200,9 +206,9 @@ class InternVLChat(BaseModel):
             assert reward_model_path is not None

-            self.reward_tokenizer = AutoTokenizer.from_pretrained(
-                reward_model_path, trust_remote_code=True, use_fast=False)
+            self.reward_tokenizer = AutoTokenizer.from_pretrained(
+                reward_model_path, trust_remote_code=True, use_fast=False, **token_kwargs)
             self.reward_model = AutoModel.from_pretrained(
                 reward_model_path,
                 torch_dtype=torch.bfloat16,
+                **token_kwargs,
@@ -337,7 +343,7 @@ class InternVLChat(BaseModel):
         assert isinstance(image_path, str)
         image = Image.open(image_path).convert('RGB')
         image = image.resize((self.image_size, self.image_size))
-        image_processor = CLIPImageProcessor.from_pretrained(self.model_path)
+        image_processor = CLIPImageProcessor.from_pretrained(self.model_path, **token_kwargs)
         pixel_values = image_processor(images=image, return_tensors='pt').pixel_values
         pixel_values = pixel_values.to(torch.bfloat16).to(self.device)